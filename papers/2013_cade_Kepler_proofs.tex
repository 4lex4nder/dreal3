\documentclass[envcountsect]{llncs}
%\usepackage{stmaryrd,amsmath,amssymb,newlfont,graphicx,caption,verbatim}
\usepackage{amsmath,amssymb,newlfont,graphicx,caption,verbatim}
\usepackage[ruled,lined,boxed,commentsnumbered,linesnumbered]{algorithm2e}
\usepackage{mathpartir}
%\usepackage{hyperref}

\newcommand{\Var}{\mathop{\mathit{Var}}}
\newcommand{\Env}{\mathop{\mathit{Env}}}
\newcommand{\dom}{\mathrm{dom}}
\newtheorem{notation}[theorem]{Notation}
\newcommand{\len}{\mathit{len}}
\newcommand{\poly}{\mathsf{poly}}
\newcommand{\ir}{\mathbb{IR}_{\cup}}

%\setlength{\textwidth}{5.3in}
%\setlength{\textheight}{8.2in}
%\setlength{\topmargin}{0in}
%\setlength{\oddsidemargin}{.6in}
%\setlength{\evensidemargin}{.6in}


\title{Extracting Proofs from a Numerically-Driven Decision Procedure}
\author{Sicun Gao \and Soonho Kong \and Michael Wang \and Edmund M. Clarke}
\institute{Carnegie Mellon University, Pittsburgh, PA 15213}

\begin{document}
\maketitle

\begin{abstract}
$\delta$-Complete decision procedures can solve SMT problems over the
reals with a wide range of nonlinear functions, allowing ``$\delta$-bounded
errors''. The scalability of such procedures usually depends on efficient
numerical procedures, whose implementation can be error-prone. It is important
for $\delta$-complete solvers to provide certificates to prove the correctness
of their answers. We show how to do this in DPLL$\langle$ICP$\rangle$, a
powerful solving framework based on Interval Constraint Propagation. We
concentrate on how to construct proof-trees for the ``unsat'' answers and how to
verify their correctness. Besides certifying solvers, we find this a promising 
approach to automated theorem proving over the reals, exploiting the power of
numerical algorithms in a formal way. One directly application of our approach
is to establish many nonlinear lemmas in the formal proof of the Kepler
Conjecture. 
\end{abstract}

\section{Introduction}

SMT formulas over the real numbers can encode a wide range of problems in
theorem proving and formal verification. Such formulas are very hard to solve
when nonlinear functions are involved~\cite{}. Our recent work on
{$\delta$-complete decision procedures} provided a new general framework for
handling nonlinear SMT problems over the reals~\cite{}. We say a decision
procedure is {\em $\delta$-complete} for a set $S$ of formulas, where $\delta$
is any positive rational number, if for any $\varphi$ from $S$ the procedure
returns one of the following answers:
\begin{itemize}
 \item {\sf unsat}: $\varphi$ is unsatisfiable.
 \item {\sf $\delta$-sat}: $\varphi^{\delta}$ is satisfiable.
\end{itemize}
Here, $\varphi^{\delta}$ is a syntactic variation of $\varphi$ that encodes a
notion of numerical perturbation on logic formulas (more
details in Section \ref{review}.) Essentially, we allow such a procedure to
give answers with one-sided, $\delta$-bounded errors. With this relaxation,
$\delta$-complete decision procedures can fully exploit the
power of scalable numerical algorithms to solve nonlinear
problems, and at the same time provide suitable correctness
guarantees for many correctness-critical problems~\cite{}. 

An important problem
for practical SMT solvers is that the correctness
of their answers should be verified. A standard approach is that, instead of
complete verification of the software programs, a solver should provide
certificates on-the-fly along with its answers. That is, when the solver
determines that a formula $\varphi(\vec x)$ is ``sat'', it produces an
assignment $\vec a$ to all the
variables such that the ground formula $\varphi(\vec a)$ is easily checked to be
true. On the other hand, when $\varphi(\vec x)$ is determined to be ``unsat'',
the solver can produce a proof $P$ that establishes the validity of $\forall
\vec x.\neg\varphi(\vec x)$ in a suitable proof system. Here, $P$ is called a
{\em proof of unsatisfiability}~\cite{}. In the framework of $\delta$-complete
decision procedures, obtaining certificates from numerically-driven SMT solvers
is especially important. Numerical algorithms usually contain complex heuristics
and floating-point operations, and it is very hard to perform static
verification on the programs directly. On the other hand, if the solutions
witnessing ``$\delta$-sat'' answers, and proofs of unsatisfiability for the
``unsat'' answers are extracted,
we can check their correctness as stand-alone using symbolic
arbitrary-precision computations. The inner mechanisms of the numerical
algorithms are not relevant in the certification process. 

From this perspective, our technique can be seen as a new approach to the challenging
task of automated theorem proving over the reals. Note that the ``unsat''
answers never contains numerical errors. Such an approach
 would combine the best of two worlds: numerical procedures are
fast but error-prone, and are used as oracles for the scalable exploration of
the search space (either searching for a $\delta$-solution, or a proof of
unsatisfiability); symbolic algorithms are precise but slow, and are used for
validating the outcome certificates, which is a much less
computationally-intensive task. 

In this paper, we show how to extract and validate such proofs
of correctness for numerically-driven SMT solvers that implement the
DPLL$\langle$ICP$\rangle$ algorithm~\cite{}, for solving nonlinear formulas over
the reals. The challenge lies in extracting symbolic proofs of unsatisfiability
that do not carry over any possible numerical errors, and the complete
validation of them as theorems in a sound proof system (ideally, containing only
simple proof rules). 

Interval Constraint Propagation (ICP)~\cite{} is a branch-and-prune algorithm
for solving systems of real constraints, which acts as the theory solver in the
DPLL(T) framework. The algorithm maintains an interval
assignment to all the variables, and update the assignments based on their
consistency with the constraints. In a ``pruning''
step, ICP contracts the intervals by pruning away subintervals that do not
contain any solution; in a ``branching'' step, ICP subdivides an interval to
create subproblems and solve them recursively. The similarity between ICP and SAT solving techniques has
been explored in the work~\cite{}. 

Our approach is as follows. We formallize the ICP algorithm in the
format of Abstract DPLL~\cite{}, and produce traces of a run of ICP. We then
use a first-order proof system, relativized to axioms of a set of real
constraints that are easy to verify, and show how to transform a run of the
Abstract ICP to a proof in the system. We then show how to validate the
generated proofs using a stand-alone symbolic proof checker. Since the proof
checker only implements simple rules that are easy to verify, it interacts with
the solver in an abstraction refinement loop (termination guaranteed) to obtain
proof trees of sufficient detail. We show experimental results on the Kepler
conjecture benchmarks. 

Our work is closely related to several lines
of research in the existing literature, which we discuss in detail in
Section~\ref{}. We will compare with symbolic approaches taken by MetiTarski
and point out the complimentrary nature of our approach to theirs. We also
compare with other ``direct'' numerical approaches in producing such proofs,
such as in the Flyspeck project, and the Bernstein polynomial approaches. 

The paper is organized as follows. 


\section{A Brief Review of $\delta$-Complete Decision Procedures}\label{review}

We first briefly review the framework of $\delta$-complete decision procedures.
It formulates a reasonable correctness requirement for solving nonlinear
formulas over the reals. We have shown that $\delta$-complete procedures exist,
with reasonable complexity bounds, for bounded SMT formulas over the reals with
arbitrary computable real functions.

To formalize computations over the reals, we first need to encode the real
numbers, as infinite strings. We can then model
computations of real functions with machines that can use infinite strings as
input and output. That is, a real function is computable if there exists a
machine that computes, using oracles that encode the arguments of the function,
the values of the function to an arbitrary precision. More precisely, these
notions are captured by the following definitions.
\begin{definition}[Encoding Real Numbers]
A {\em name} of a real number $a\in \mathbb{R}$ is a function
$\mathcal{\gamma}_a: \mathbb{N}\rightarrow \mathbb{Q}$ satisfying that for all
$i\in \mathbb{N}$, $|\gamma_a(i) - a|<2^{-i}.$ For $\vec a\in \mathbb{R}^n$,
$\gamma_{\vec a}(i) = \langle \gamma_{a_1}(i), ..., \gamma_{a_n}(i)\rangle$, and
$\Gamma(\vec a) = \{\gamma: \gamma\mbox{ is a name of }\vec a\}$.
\end{definition}
\begin{definition}[Computable Real Functions] We say
$f:\subseteq\mathbb{R}^n\rightarrow \mathbb{R}$ is computable, if there exists
an oracle Turing machine $\mathcal{M}_f$ that performs the following
computation: Let $\vec a\in \dom(f)$ be any argument of $f$ and $\gamma(\vec a)$
any name of $\vec a$. On any input $i\in \mathbb{N}$,
$\mathcal{M}_f^{\gamma(\vec a)}(i)$ uses $\gamma(\vec a)$ as an oracle, and
computes a $2^{-i}$-approximation to $f(\vec a)$.
\end{definition}
Most common continuous real functions are computable, such as addition,
multiplication,  absolute value, $\min$, $\max$, $\exp$, $\sin$ and solutions of
Lipschitz-continuous ordinary differential equations~\cite{CAbook}. Compositions
of computable functions are computable.

We now let $\mathcal{F}$ denote an arbitrary collection of computable real
functions. $\mathcal{L}_{\mathcal{F}}$ denotes the first-order signature over
the structure $\mathbb{R}_{\mathcal{F}} = \langle
\mathbb{R}, \leq, \mathcal{F}\rangle$. We can then consider SMT problems
over $\mathbb{R}_{\mathcal{F}}$, namely, satisfiability of quantifier-free
$\mathcal{L}_{\mathcal{F}}$-formulas over $\mathbb{R}_{\mathcal{F}}$. We
consider bounded SMT problems, which is more conveniently expressed as
$\Sigma_1$-sentences with bounded quantifiers as follows. We say a
$\Sigma_1$-sentence is bounded, if it can be written in the form
$$\varphi:\ \exists^{I_1}x_1\cdots \exists^{I_n}x_n. \psi(x_1,...,x_n)$$
where: for all $i$, $I_i\subseteq \mathbb{R}$ is a bounded (open or closed)
interval; each bounded quantifier $\exists^{I_i}x_i.\phi$ denotes $\exists
x_i.(x_i\in I_i\wedge \phi)$. $\psi(x_1,...,x_n)$ is a quantifier-free
$\mathcal{L}_{\mathcal{F}}$-formula, i.e., a Boolean combination of atomic
formulas of the form $f(x_1,...,x_n)\circ 0$, where $f$ is a composition of
functions in $\mathcal{F}$ and $\circ\in\{<,\leq, >, \geq, =, \neq \}$.
All the functions occurring in $\psi(\vec x)$ should be defined everywhere over
the closure of $I_1\times\cdots \times I_n$.

An immediate observation is that any bounded $\Sigma_1$-sentence
can be put into the following standard form, where inequalities are implicitly
expressed by the bounds on quantifiers (introducing slack variables) and the
atomic formulas only involve equalities.
\begin{proposition}[Standard Form]\label{pre1}
Any bounded $\Sigma_1$-sentence $\varphi$ in $\mathcal{L}_{\mathcal{F}}$ is
equivalent over $\mathbb{R}_{\mathcal{F}}$ to a sentence of the form
$\exists^{I_1}x_1\cdots \exists^{I_n}x_n(\bigwedge_{i=1}^m(\bigvee_{j=1}^{k_i}
f_{ij}(\vec x)=0)).$
\end{proposition}

We can now define the notion of ``$\delta$-perturbations'' on these
formulas.
\begin{definition}[$\delta$-Weakening and Perturbations]\label{weak-def}
Let $\delta\in \mathbb{Q}^+\cup\{0\}$ be a constant and $\varphi$ be a
$\Sigma_1$-sentence in standard form:
%\vspace{-.3cm}
\[\varphi:= \exists^{\vec I}\vec x\;(\bigwedge_{i=1}^m (\bigvee_{j=1}^{k_i}
f_{ij}(\vec x)= 0)).
%\vspace{-.3cm}
\]
The $\delta$-weakening of $\varphi$ defined as:
%\vspace{-.3cm}
\[\varphi^{\delta}:= \exists^{\vec I} \vec x\;(\bigwedge_{i=1}^m(\bigvee_{j=1}^k
|f_{ij}(\vec x)|\leq \delta)).\]
Also, a $\delta$-perturbation is a constant vector $\vec c =
(c_{11},...,c_{mk_m})$, where $c_{ij}\in\mathbb{R}$ and $||\vec
c||\leq\delta$, such that the $\vec c$-perturbed form of $\varphi$ is given by:
%\vspace{-.2cm}
\[\varphi^{\vec c}:= \exists^{\vec I} \vec x\;(\bigwedge_{i=1}^m(\bigvee_{j=1}^k
f_{ij}(\vec x) = c_{ij})).\]
\end{definition}

\begin{definition}[Bounded $\delta$-SMT in $\mathcal{L}_{\mathcal{F}}$] Let
$\mathcal{F}$ be a finite collection of Type 2 computable functions. Let
$\varphi$ be a bounded $\Sigma_1$-sentence in $\mathcal{L}_{\mathcal{F}}$ in
standard form. The {\em bounded $\delta$-SMT problem} asks for one of the
following two decisions on $\varphi$:
\begin{itemize}
\item $\mathsf{unsat}:$ $\varphi$ is false.
\item $\delta$-$\mathsf{sat}:$ $\varphi^{\delta}$ is true.
\end{itemize}
When the two cases overlap, either decision can be returned.
\end{definition}

The main theoretical result in this framework is that for any positive
$\delta$, the bounded $\delta$-SMT problems in $\mathcal{L}_{\mathcal{F}}$ are
decidable (namely, $\delta$-decision
procedures exist).
\begin{theorem}[Decidability] Let $\mathcal{F}$ be any collection
of computable real functions and $\delta\in \mathbb{Q}^+$. The bounded
$\delta$-SMT
problem in $\mathcal{L}_{\mathcal{F}}$ is decidable.
\end{theorem}

The $\delta$-SMT problems also have reasonable complexity bounds for various
signatures that would otherwise define undecidable theories.
\begin{theorem}[Complexity]
Let $\mathcal{F}$ be a finite set of functions in Type 2 complexity class
$\mathsf{C}$, $\mathsf{P}\subseteq\mathsf{C}\subseteq\mathsf{PSPACE}$. The
$\delta$-SMT problem for uniformly bounded $\Sigma_1$-classes in
$\mathcal{L}_{\mathcal{F}}$ is in $\mathsf{NP^C}$.

For instance, when $\mathcal{F}$ only contains polynomial-time
computable real functions such as $\{+, \times, \exp, \sin\}$,
the $\delta$-SMT problem is $\mathsf{NP}$-complete.
\end{theorem}

These results lead to a
new perspective on decision problems over the reals in general.
This framework provides a theoretical basis for the development of
numerically-driven decision procedures such as~\cite{}.

\section{Proof Systems for Interval Constraint Propagation}\label{icp}

\subsection{Interval Constraint Propagation}

The method of Interval Constraint Propagation (ICP)~\cite{handbookICP} finds
solutions of real constraints using a ``branch-and-prune" method, combining
interval arithmetic and constraint propagation. The idea is to use interval
extensions of functions to ``prune'' out sets of points that are not in the
solution set, and ``branch'' on intervals when such pruning can not be done,
until a small enough box that may contain a solution is found. A high-level
description of ICP is given in Algorithm~\ref{algo1}.
\begin{algorithm}[h!]
\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
\Input{Constraints $c_1,...,c_m$, initial box $B^0
= I^0_1\times \cdots \times I^0_n$, box stack $S=\emptyset$, and precision
$\varepsilon\in \mathbb{Q}^+$.}
\Output{{\sf sat} or {\sf unsat}.}
\BlankLine
$S.\mathrm{push}(B_0)$\;
\While{$S\neq \emptyset$}{\label{while}
$B\leftarrow S.\mathrm{pop}()$ \;
\While{$\exists 1\leq i \leq m, B\neq \mathrm{Prune}(B,f_i)$}{
%\For{$j\leftarrow 1$ \KwTo $m$}{
        $B\leftarrow\mathrm{Prune}(B, f_i)$ \;
%       \If{$B=\emptyset$}{break\;}
}
\If{$B\neq \emptyset$}
{\eIf{$\exists 1\leq i\leq n, |I_i|\geq \varepsilon$}{$\{B_1,B_2\}\leftarrow
\mathrm{Branch}(B, i)$\;$S.\mathrm{push}(\{B_1,B_2\})$\;}{return {\sf sat}\;}}
}
return {\sf unsat}\;
\caption{High-Level ICP$_{\varepsilon}$ (decision version of
Branch-and-Prune)\label{algo1}}
\end{algorithm}

In Algorithm~\ref{algo1}, Branch$(B,i)$ is an operator that returns two smaller
boxes $B' = I_1\times\cdots\times I_i'\times\cdots\times I_n$ and $B''=I_1\times
\cdots\times I_i''\times \cdots\times I_n$, where $I_i\subseteq I_i'\cup
I_i''$. The $\mathrm{Prune}(B, f)$ operation is a key component of the power of
ICP. In principle, any operation that contracts the interval assignments on the
variables can be used as pruning. In practice, various rules for pruning
operators need to be used to ensure correctness and efficiency~\cite{}, and we
do not go into more details now.

Our focus now is to formalize ICP algorithms so that we can extract symbolic proofs from
its computation process. The branch-and-prune structure of ICP is very similar
to DPLL SAT solving, and we follow the representation framework of abstract
DPLL~\cite{}. We represent ICP as a transition system, with states consisting of
interval assignments and constraints.
\begin{definition}[Intervals]
An interval $I$ is any connected subset of $\mathbb{R}$. We write $\mathbb{IR}$
to denote all the set of all intervals in $\mathbb{R}$. The set of all finite
unions of intervals is $\mathbb{IR}_{\cup} = \{\bigcup_{i=1}^k I_i:
I_i\in\mathbb{IR}\}.$
\end{definition}
\begin{definition}[Interval Assignment Sequence]
Let $x_1,...,x_n$ be real variables. An interval assignment sequence over
$\vec x$ is a sequence of the form $(s_1,...,s_m)$, where
$$s_i\in \{(x_i\in I_j): 1\leq i\leq n, I_j\in
\mathbb{IR}_{\cup}\}\cup\{(x_i\in I_j)^d: 1\leq i\leq n, I_j\in
\mathbb{IR}_{\cup}\}.
$$
We write $(S_1, S_2)$ to denote the concatenation of two sequences $S_1$ and
$S_2$. The parentheses can be omitted when appropriate. 
\end{definition}
\begin{definition}[Box Domain]
Let $S$ be an interval assignment sequence over variables $x_1,...,x_n$. The box
domain associated with $S$ is defined by
$$\beta(S) = I_1\times\cdots \times I_n, \mbox{ where }I_i = \bigcap\{ I:
(x_i\in
I)\mbox{ or } (x_i\in I)^d \mbox{ occurs in } S\}.$$
Also, we write $\beta(S)_i$ to denote $I_i$. 
\end{definition}

\begin{definition}[ICP Transitions] We define the following transition rules.
We write $c(\vec x)$ to denote an arbitrary constraint over $\mathbb{R}^n$, and
$S$ an interval assignment sequence over $\vec x$.

\paragraph{Pruning:}
\begin{eqnarray*}
S\parallel c &\Longrightarrow& S, (x_i\in I_i')\parallel c,
\end{eqnarray*}
under the condition that $\forall \vec a\in \beta(S,x_i\in
I_i\setminus I_i')$,
$c(\vec a)$ is false, where $\beta(S_i) = I_i$.
\paragraph{Branching:}
\begin{eqnarray*}
S\parallel c &\Longrightarrow& S, (x_i\in I_i)^d \parallel c,
\end{eqnarray*}
under the condition that $I_i\subseteq \beta(S_i)$.

\paragraph{Backtracking:}
\begin{eqnarray*}
S, (x_i\in I_i)^d, S'\parallel c &\Longrightarrow& S, (x_i\in
I_i\setminus I_i') \parallel c,
\end{eqnarray*}
under the condition that $\forall a\in \beta(S, (x_i\in I_i)^d, S')$, $c(\vec
a)$
is false.

\paragraph{Fail:}
\begin{eqnarray*}
S\parallel c &\Longrightarrow& \emptyset \parallel c
\end{eqnarray*}
under the condition that $\forall \vec a\in \beta(S)$, $c(\vec a)$ is false and
 $S$ has no decision elements.
\end{definition}


As usual, the transitions are all {\em may} transitions, not {\em must}
transitions.
\begin{remark}
The difference between the transitions here from abstract DPLL is:
1. The assignments are not starting from empty, but contracted.
2. backtracking?
3. branching can be very nondeterministic
\end{remark}
\begin{definition}[Abstract ICP]
An ICP framework is a transition system
$$\langle \mathbb{IR}_{\cup}^n, \mathcal{C}, \Longrightarrow,
\varepsilon\rangle$$
where $\mathcal{C}$ is any set of constraints over $\mathbb{R}^n$.
$\Longrightarrow: \mathbb{IR}_{\cup}^n\times
\mathcal{C}\rightarrow \mathbb{IR}_{\cup}^n\times \mathcal{C}$ is the transition
relations defined above, and $\varepsilon\in \mathbb{Q}^+$ is an
error bound.

A {\em run} of ICP is any sequence
$$S_1\parallel c, ... , S_k\parallel c$$
where $S_k$ is either $\emptyset$, or $S_k\neq \emptyset$ and
$||\beta(S_k)||<\varepsilon$.
\end{definition}
\begin{remark}
We have defined ICP in a general way, without enforcing conditions
on the pruning operators, such as well-definedness as in~\cite{}. Thus, many
invalid ICP runs can be generated. This is
because here we will treat ICP as a proof searching algorithm, and rely on the
proof checkers to determine the correctness of an ICP run. In practice, of
course, only
``correct" ICP algorithms can provide proofs that can always be validated.
\end{remark}




\paragraph{Witness of $\delta$-Satisfiability}
For satisfiable formulas, a witness for $\delta$-satisfiability can be
easily obtained.


\subsection{First-Order Proofs of Unsatisfiability}

We focus on proving the unsatisfiability of SMT problems of the form
$$\exists^{I_1} x_1\cdots \exists^{I_n} x_n \bigwedge_{i=1}^m
f_i(x_1,...,x_n)\sim 0$$
where $\sim \in \{=,\neq, >, \geq, <, \leq\}$. That is, we prove the validity
of formulas of the form:
$$\forall x_1 \cdots \forall x_n (x_1\in I_1\wedge \cdots \wedge x_n\in I_n
\rightarrow \bigvee_{i=1}^m f_i(x_1,...,x_n)\sim 0)$$

We will show that the steps in ICP can be certified by translating them
reversely to a standard first-order proof. Although various real functions are
involved, to verify the proof correctness of ICP sequences we only need a weak
system of first-order logic reasoning.

\begin{definition}[Language]
\Bigg({\bf todo} change the language to treat I as conventions, and do not use
unions of intervals.\Bigg) We fix a signature $\mathcal{L}_I = \langle
\mathbb{IR}, <, \mathcal{F} \rangle$
 where $\mathbb{IR}$ is the union closure of real intervals, but used as {\em unary
predicates}. Naturally, for any $I\in \mathbb{R}$, $I(x)$ can be written as
$x\in I$. $\mathcal{F}$ is a set of computable real functions.
\end{definition}

\begin{definition}[System $\mathbb{D}_A$]
We define $\mathbb{D}_A$ to be the first-order proof system consisting of only the
following two rules:
\paragraph{$\vee$-Intro}\begin{mathpar}
  \inferrule{
  \forall x (\psi \rightarrow \varphi)
    \and
  \forall x (\psi' \rightarrow \varphi)
  }
  {
  \forall x ( \psi\vee \psi' \rightarrow \varphi)
  }\end{mathpar}
\paragraph{$\forall$-MP}
\begin{mathpar}
  \inferrule{
  \forall x (\psi \rightarrow \varphi)
    \and
  \forall x (\psi' \rightarrow \psi)
  }
  {
  \forall x (\psi' \rightarrow \varphi)
  }
\end{mathpar}
and a set $A$ of axioms of the following two types:
\paragraph{Interval Axioms}
\begin{mathpar}
\inferrule{ }{\forall x (x\in I \rightarrow x\in I_1 \vee x\in I_2 )}
\end{mathpar}
\paragraph{Function Axioms}
\begin{mathpar}
\inferrule{ }{\forall x ( x\in I \rightarrow f(x)\in I')}
\end{mathpar}
\end{definition}

Derivations in $\mathbb{D}_A$ are as standardly defined. Clearly, the two
first-order rules are valid. Thus, as long as the axioms chosen are valid,
 the system can only produce valid formulas over $\mathbb{R}$.

\begin{remark}
Relations to resolution proofs. 
\end{remark}


\begin{proposition}[Relative Soundness of $\mathbb{D}_A$]
If $\mathbb{D}_A\vdash \varphi$ and $\mathbb{R}\models \bigwedge A$, then $\mathbb{R}\models \varphi$.
\end{proposition}

We now describe the construction of proof trees from ICP runs. The proof trees in
our case will be labelled binary trees. We describe a tree as a tuple $T =
\langle V, V_L,  \Sigma, \delta, \sigma\rangle$. $V = \{v_0, ..., v_k\}$,
$k\in \mathbb{N}$, is a finite set of nodes, where $v_0\in V$ always denotes the
root
node. $\Sigma$ is a set of labels, which in our case is the set of
$\mathcal{L}_I$-formulas. $\delta:\subseteq V\times \{l,r\} \rightarrow V$ is a
partial mapping from a node to descendent nodes, where $\delta(v, l)$ and
$\delta(v, r)$ denote the left and right descendent nodes, respectively.
$\sigma: V\rightarrow \Sigma$ is a labeling function that maps each node
$v\in V$ to a formula $\sigma(v) \in \Sigma$. In addition, the edges in the
tree can be labelled as well, through a function $\tau: V\times V\times \Omega$
where $\Omega$ is a set of edge-labels. 

\subsubsection{Tree Generation} Let 
$$S_0\parallel c\Longrightarrow^{t_1} \cdots
\Longrightarrow^{t_m} S_m\parallel c $$
be an ICP run such that the ending state
is fail. We now define the procedure by defining the functions $\delta$ and
$V_L$ through induction on $s_i$. We also define labels on the edges along the
process, with $\omega$ = \{{$\vee$-Intro}, MP, I-Ax, F-Ax\}. 

\paragraph{Case $i= m$.} We label the root node $v_0$ by 
$$\sigma(v_0) := \forall \vec x( \vec x\in \beta(S_1) \rightarrow \neg c).$$
Also, let $V_L^0= \{\delta(v_0,l), \delta(v_0, r)\}$ denote the current
collection of leaf nodes. 


%{\tt it's
%probably better to define a leaf set and make the children mappings partial.
%Otherwise it's cumbersome to talk about the leaves and the ones without
%assigned formulas. }


\paragraph{Case $i = k+1$ ($1< k \leq m$). }
Suppose $V_L$ and $\sigma$ is defined for $s_1, ...,s_k$. Write $s_k = S_k
\parallel c$ and $s_k = S_{k+1} \parallel c$. Now we split
the cases on the type of the step $t$ from $s_i$ to $s_{i+1}$ as follows. 
\paragraph{(Pruning Step)} Suppose $s_k\Longrightarrow^{t_{k+1}} s_{k+1}$ is a
pruning. That is, 
$$S\parallel c \Longrightarrow S, (x_i\in I_i')\parallel c,$$
under the condition that $\forall \vec a\in \beta(S,x_i\in I_i\setminus I_i')$,
$c(\vec a)$ is false.

This step corresponds to the following sub-tree of the proof. If we write 
$$\vec I_1 = \beta(S, (x_i\in I_i')), \vec I_2 = \beta(S, (x_i\in I_i\setminus
I_i')), \mbox{ and } \vec I= \beta(S),$$ then we have 
{\small
\begin{mathpar}
\inferrule{\inferrule{
  \inferrule{\vdots}{\forall \vec x (\vec x\in \vec I_1 \rightarrow \neg c)}
    \and
    \inferrule{\ }
    {
      \forall \vec x (\vec x \in \vec I_2 \rightarrow\neg c)
      }\mbox{F-Ax}
   }
  {
  \forall x (\vec x\in \vec I_1\vee \vec x \in \vec I_2 \rightarrow \neg c)
  }\mbox{$\vee$-I}
  \and
  {
  \inferrule{\ }{\forall \vec x ( \vec x\in \vec I\rightarrow(\vec x \in \vec
I_1 \vee \vec x\in \vec I_2))}\mbox{I-Ax}
  }
  }
{
\forall \vec x (\vec x\in\vec I \rightarrow \neg c)
}\mbox{$\forall$-MP} 
   \end{mathpar}
} 

Formally, we define the following. Let $v\in V_L^k$ be a leaf node in $T^k$ such
that $$\sigma(v) = \forall \vec x (\vec x\in\vec I \rightarrow \neg c).$$ 
We then define
\begin{eqnarray*}
\delta(v, l) &=& v_{k+1}^1, \sigma(v_{k+1}^1) = \forall \vec x
( \vec x \in \vec I_1 \vee \vec x \in \vec I_2 \rightarrow \neg c); \\
\delta(v, r) &=& v_{k+1}^2, \sigma(v_{k+1}^2) = \forall \vec x ( \vec x\in \vec
I\rightarrow(\vec x \in \vec I_1 \vee \vec x\in \vec I_2));\\
 \delta(v_{k+1}^1, l) &=& v_{k+1}^3, \sigma(v_{k+1}^3) = \forall x (\vec x\in
\vec I_1\vee \vec x \in \vec I_2 \rightarrow \neg c)\\
 \delta(v_{k+1}^1, r) &=& v_{k+1}^4, \sigma(v_{k+1}^4) = \forall \vec x (\vec x
\in \vec I_2 \rightarrow\neg c)
  \end{eqnarray*}
and set $V_L^{k+1} = V_L^k \cup \{v_{k+1}^2, v_{k+1}^4\}$. 
  
  
\paragraph{(Branching Case)}Suppose $s_k\Longrightarrow^{t_{k+1}} s_{k+1}$ is a
branching step. That is, 
\begin{eqnarray*}
S\parallel c &\Longrightarrow& S, (x_i\in I_i)^d \parallel c,
\end{eqnarray*}
under the condition that $I_i\subseteq \beta(S_i)$.

This step corresponds to the following sub-tree of the proof. If we write 
$$\vec I_1 = \beta(S, (x_i\in I_i')), \vec I_2 = \beta(S, (x_i\in I_i\setminus
I_i')), \mbox{ and } \vec I= \beta(S),$$ then we have 
{\small
\begin{mathpar}
\inferrule{\inferrule{
  \inferrule{\vdots}{\forall \vec x (\vec x\in \vec I_1 \rightarrow \neg c)}
    \and
    \inferrule{\vdots }
    {
      \forall \vec x (\vec x \in \vec I_2 \rightarrow\neg c)
      }
   }
  {
  \forall x (\vec x\in \vec I_1\vee \vec x \in \vec I_2 \rightarrow \neg c)
  }\mbox{$\vee$-I}
  \and
  {
  \inferrule{\ }{\forall \vec x ( \vec x\in \vec I\rightarrow(\vec x \in \vec
I_1 \vee \vec x\in \vec I_2))}\mbox{I-Ax}
  }
  }
{
\forall \vec x (\vec x\in\vec I \rightarrow \neg c)
}\mbox{$\forall$-MP} 
   \end{mathpar}
} 

Formally, we define the following. Let $v\in V_L^k$ be a leaf node in $T^k$ such
that $$\sigma(v) = \forall \vec x (\vec x\in\vec I \rightarrow \neg c).$$ 
We then define 
\begin{eqnarray*}
\delta(v, l) &=& v_{k+1}^1, \sigma(v_{k+1}^1) = \forall \vec x
( \vec x \in \vec I_1 \vee \vec x \in \vec I_2 \rightarrow \neg c); \\
\delta(v, r) &=& v_{k+1}^2, \sigma(v_{k+1}^2) = \forall \vec x ( \vec x\in \vec
I\rightarrow(\vec x \in \vec I_1 \vee \vec x\in \vec I_2));\\
 \delta(v_{k+1}^1, l) &=& v_{k+1}^3, \sigma(v_{k+1}^3) = \forall x (\vec x\in
\vec I_1\vee \vec x \in \vec I_2 \rightarrow \neg c)\\
 \delta(v_{k+1}^1, r) &=& v_{k+1}^4, \sigma(v_{k+1}^4) = \forall \vec x (\vec x
\in \vec I_2 \rightarrow\neg c)
  \end{eqnarray*}
and set $V_L^{k+1} = V_L^k \cup \{v_{k+1}^2 \}$.
  


\paragraph{(Backtracking Case)}Suppose $s_k\Longrightarrow^{t_{k+1}} s_{k+1}$ is
a branching step. That is, 
\begin{eqnarray*}
S, (x_i\in I_i)^d, S'\parallel c &\Longrightarrow& S, (x_i\in
I_i\setminus I_i') \parallel c,
\end{eqnarray*}
under the condition that $\forall a\in \beta(S, (x_i\in I_i)^d, S')$, $c(\vec
a)$
is false.

This step corresponds to the following sub-tree of the proof. If we write 
$$\vec I_1 = \beta(S, (x_i\in I_i')), \vec I_2 = \beta(S, (x_i\in I_i\setminus
I_i')), \mbox{ and } \vec I= \beta(S),$$ then we have 
{\small
\begin{mathpar}
\inferrule{\inferrule{
  \inferrule{\vdots}{\forall \vec x (\vec x\in \vec I_1 \rightarrow \neg c)}
    \and
    \inferrule{\vdots }
    {
      \forall \vec x (\vec x \in \vec I_2 \rightarrow\neg c)
      }
   }
  {
  \forall x (\vec x\in \vec I_1\vee \vec x \in \vec I_2 \rightarrow \neg c)
  }\mbox{$\vee$-I}
  \and
  {
  \inferrule{\ }{\forall \vec x ( \vec x\in \vec I\rightarrow(\vec x \in \vec
I_1 \vee \vec x\in \vec I_2))}\mbox{I-Ax}
  }
  }
{
\forall \vec x (\vec x\in\vec I \rightarrow \neg c)
}\mbox{$\forall$-MP} 
   \end{mathpar}
} 

Formally, we define the following. Let $v\in V_L^k$ be a leaf node in $T^k$ such
that $$\sigma(v) = \forall \vec x (\vec x\in\vec I \rightarrow \neg c).$$ 
We then define 
\begin{eqnarray*}
\delta(v, l) &=& v_{k+1}^1, \sigma(v_{k+1}^1) = \forall \vec x
( \vec x \in \vec I_1 \vee \vec x \in \vec I_2 \rightarrow \neg c); \\
\delta(v, r) &=& v_{k+1}^2, \sigma(v_{k+1}^2) = \forall \vec x ( \vec x\in \vec
I\rightarrow(\vec x \in \vec I_1 \vee \vec x\in \vec I_2));\\
 \delta(v_{k+1}^1, l) &=& v_{k+1}^3, \sigma(v_{k+1}^3) = \forall x (\vec x\in
\vec I_1\vee \vec x \in \vec I_2 \rightarrow \neg c)\\
 \delta(v_{k+1}^1, r) &=& v_{k+1}^4, \sigma(v_{k+1}^4) = \forall \vec x (\vec x
\in \vec I_2 \rightarrow\neg c)
  \end{eqnarray*}
and set $V_L^{k+1} = V_L^k \cup \{v_{k+1}^2, v_{k+1}^4\}$.
  

\paragraph{(Fail Case)} Suppose it is a failure step. That is, 
\begin{eqnarray*}
S\parallel c &\Longrightarrow& \emptyset \parallel c
\end{eqnarray*}
under the condition that $\forall \vec a\in \beta(S)$, $c(\vec a)$ is false and
 $S$ has no decision elements.

 This step corresponds to the following sub-tree of the proof. Let $\vec I
=\beta(S)$. 
\begin{mathpar}
 \inferrule{\ }{\forall \vec x ( \vec x\in \vec I) \rightarrow \neg
c}\mbox{F-Ax}
\end{mathpar}
 
 In all, the tree constructed is $T^m = \langle V, \bigcup_k V_L^k, \delta,
\sigma\rangle$. 

\begin{theorem}\label{successful_tree}
The tree construction procedure produces a unique tree that is valid natural
deduction tree in $D_A$. 
\end{theorem}

\begin{example}
Give an example of tree construction.
\end{example}

In this way, we see ICP as a proof searching algorithm for valid universal
formulas. Note that following soundness, once the proof tree is constructed and
can be validated, the details of the ICP algorithm no longer matter. This serves
our goal of obtaining a stand-alone certificate that can be checked with
external checkers.

\begin{proposition}
 The size of the proofs is linear in the computation steps, which can be
exponential in the size of the problems. 
\end{proposition}

We will see that this generates proof traces on a gigabyte scale in
Section~\ref{}. 




\subsection{Validating the Axioms}

It is clear that the proof rules in the proof trees are simple first-order
rules. The tricky part is the axioms that are introduced in various
steps. Following relative soundness, the validity of the formulas now rely on the
correctness of these axioms.

For the interval axioms without functions of the form $\forall x(x\in I_1\vee
x\in I_2\rightarrow x\in I)$, we only need to check that $I$ is a superset of
$I_1\cup I_2$. This is an easy task.

For the axioms with functions, which are of the form
$$\forall x (x\in I \rightarrow f(x)\sim 0)$$
we need to verify them using nontrivial properties of the functions. Note that
the form of these axioms is the same as the full problem. However, the
difference is that these axioms are invoked when $I$ is relatively small, and
the value of $f$ can usually be determined. In general, these axioms are
verified if we can use basic interval arithmetic facts to certify them, which is
a topic of this section.

\begin{definition}[Interval Extensions]
Let $f: \mathbb{R}^n\rightarrow \mathbb{R}$ be a real function. An interval
function $F: \mathbb{IR}^n \rightarrow \mathbb{IR}$ is a function that
satisfies:
$$\forall I\in \dom(F), \{f(x): x\in I\}\subseteq F(I).$$
\end{definition}

A simple example of interval extensions is the natural interval extension for
arithmetic operations, based computations of the end points of the intervals.
\begin{example}[Natural Extensions]
The natural extensions of $\{+, -, \times, \div\}$ are as follows.
\end{example}

\begin{proposition}
Let $F$ be an interval extension of $f$, and $I\subseteq \dom(f)$. We have:
\begin{center}
If $F(I)\subseteq A$, then $\forall x (x\in I \rightarrow f(x)\in A)$.
\end{center}
\end{proposition}
Thus, if we can verify that all the interval extensions are consistent with the
function axioms, then we can validate the axioms.

\begin{remark}
Note that we generate the axioms dynamically, without presuming any set of
existing axioms.  
\end{remark}

\begin{remark}
We regard simple real arithmetic as easy tasks.
As is the case in validating the witnesses, the interval axioms, the function
axioms. This needs to be justified, since numerical computations always involve
floating point computations that are fallible. In practice, once a proof is
obtained, there can be multiple ways to verify the proof. For instance, symbolic
computations with precise arithmetic can be used.
\end{remark}

\section{Proof Refinement Algorithm: Branch and Prove}

The challenge for a proof checking algorithm is that the pruning operations in
ICP usually implements complicated heuristics that is more powerful than
interval arithmetic. However, in the proof we can hardly simulate those
heuristics, unless we are willing to formalize all the detailed heuristics of
the numerical computation involved. Thus, we propose an abstraction refinement
loop ``Branch and Prove'' that allows produces proof traces of the right amount
of details following through interactions between the prover and the solver. 

\begin{example}
Give an example of how dReal solves in one step that is beyond the validation
power of simple interval arithmetic.
\end{example}

Our approach is the following. When we run the solver, we obtain a proof trace
following the construction procedure defined above. Then the proof checker
verifies the structure of the tree following the first-order rules, and reduce
the problem to the verification of the ``axioms'' on the leaf notes of the
proof tree. Next, when it fails to prove the axioms through safe (but naive)
interval arithmetic, it generates new subproblems and ask the solver to return
new traces. At this stage, the axioms becomes the new theorems to be proved.
This is an abstraction refinement procedure, by executing the loop, we obtain
proof trees that contain more and more detailed steps, which may in the end be
completely verified by the proof checker. 

There are two ways that the prover can generate the subproblems. One is to
branch on a variable in the formula, so that the solver can solve the same
problem on a smaller domain. The other option is to have the solver to run the
same problem, but with a smaller $\delta$. In this way, the solver takes in the
subproblem as a new task, and produce refined proof trajectories, which,
because of the reduced size of the domains, may use less tricky heurstics to
solver. We continue this loop to obtain more and more refined proof trees, and
see if the proof checker can verify the subtrees. We give the algorithm in
Algorithm~\ref{algo1}. 

\begin{example}
 
\end{example}

Note that under the condition that the pruning operators in the solver is
well-defined (detailed definition in~\cite{}), both procedures never change the
unsat result. The procedure on branching always terminates, but may give
exponentially many new problems; while the $\delta$-change does not give new
problems, but may exponentially slow down the solver in each round. Still, we
can prove the reliability of the refinedment loop in that it always terminates
(the prover can fail to prove), producing verified sub-theorems in the system. 
\begin{proposition}
The branch and prove loop is terminating, and does not give wrong answers. 
\end{proposition}
\begin{proof}
\end{proof}

\begin{algorithm}
\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
\Input{
A proof tree $T$.
}
\Output{{\sf validated} or {\sf rejected}.}
\BlankLine
\While{Axioms are not validated}{\label{while}
Loop between solver and checker\;
}
return {\sf rejected}\;
\caption{Branch and Prove\label{algo1}}
\end{algorithm}


\section{Case Study: Proving Lemmas for the Kepler Conjecture}

Our open-source tool dReal is available at. The main motivation for us to build
the proof checker is for making contribution to the flyspeck project is led
by Tom hales in University of Pittsburgh. 

\subsubsection{The Kepler Conjecture}

The typical formulas contain trigonmetric inequalities.

\subsubsection{Solving Statistics}

\input{good_benchmarks.tex}

\subsubsection{Proofs Generated}

\input{good_proofs.tex}

\subsubsection{Debugging Benefits}


\subsubsection{Towards Complete Verification}




\section{Related Work}

Our work is closely related to several lines of exisiting work. The the
project of MetiTarski. The key new concept is to use numerical methods as
guiding the search for proofs. Overapproximations of numerical values of
functions are used, but always safe and can be validated with symbolic
procedures. Both have strength and should be combined as mixed strategy. Our
work can be seen as an instance of performing certifiable computation.
MetiTarski. The axioms in our case are generated on the fly, and we do not have
a fixed set of axioms. The key concept change is this. Actually, they can be
combined as MetiTarski can solve
complicated axioms. 
Generating proofs from solvers has been the focus for
many theories. SAT solvers ... . The idea of certifying computation has been
investigated in formal detail in~\cite{}. Note that MetiTarski uses the same
approach -- assuming that there are axioms by symbolic external solvers. 

MetiTarski needs axioms to reduce to polynomials, and then polynomials to be
verifying by outside solvers. Note that the outside solvers are not verified,
and actually hard to be verified. The numerical approach, on the other hand,
can rely on any external solver that are easy to be verified by multiple
solvers, and can be done symbolically. Once it is done symbolically, we obtain
a symbolic proof that does not mention any numerical computations. 

The following benchmark can be solved by MetiTarski, which is used in verifying
the aircraft example in~\cite{}. 
\begin{example}[Aircraft]
The aircraft formula is
\begin{eqnarray*}
& &\forall t \forall x_1\forall x_2 \forall y_1\forall y_2\forall
d_1\forall d_2\forall e_1\forall e_2. \\
& &0<t<10\wedge x_1<-9 \wedge x2<-1\wedge
x1>10 \wedge y2>10\\
& & \wedge 0.1<d1< 0.15\wedge 0.1<d_2<0.15 \wedge
0.1<e-1<0.15\wedge 0.1<e_2<0.15 \\
\rightarrow & &\Big(
\Big(x_1-y_1-100d_2-100e_2+(100d_2+100e_2)\cos(0.01t)\\
& &\ \ \ + (100d_1
-100e_1)\sin(0.01t)\Big)^2\\
& & \ \ +\Big((x_2-y_2+100d_1+100e_1+(-100d_1-100e_1)\cos(0.
0 1 t ) \\
& &\ \ \  + (100d_2 - 100e_2)\sin(0.01t)\Big)^2 > 2\Big).
\end{eqnarray*}
The formula is solved in MetiTarski in 924
seconds~\cite{}. On comparable machines, dReal solves in 0.01 seconds, also
completely verifies the proof of unsatisfiability in 0.41 seconds. Note that
this may be the first full proof produced that do not rely on external decision
procedures. 
\end{example}
On the other hand, numerical approach has its inherent limitations. For
instance, for simple formulas in the MetiTarski benchmark set such as the
following, our solver keeps returning $\delta$-sat, and thus do not provide a
proof of unsatisfiability. 
\begin{example}
 
\end{example}

Franzle's paper. Old validation papers. proof of unsatisfiability of SAT and
SMT solvers. Theorem proving papers.

The nature of the prune and prove approach is like finding better and better
Taylor expansions. 

Hale's work, of course. 

Berstein polynomials from nasa. 

Thomas Hales implemented an infor-
mal verification procedure based on interval arithmetic with Taylor
approximations which
can completely verify all Flyspeck nonlinear inequalitie

``The main difficulty is finding a suitable partition.'' Instead of using
arbitrary branching, we rely on numerical facts that does the pruning for us,
and 

Ceritifying computations literature. 


\section{Conclusion and Future Work}

We believe this is a right starting point for the final solution of the Kepler
conjecture. What is needed now is a verified HOL library of interval facts, and
a verified implementation of the prover. 

More Boolean structures are needed 

\bibliographystyle{abbrv}
\bibliography{tau}

\newpage
\section*{Appendix}


\begin{proof}(Proof of Theorem~\ref{successful_tree})
We need to show that the proof construction is always successful. 

\end{proof}





\end{document}

